{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tw_sentiment</th>\n",
       "      <th>tw_followers</th>\n",
       "      <th>reddit_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1519997640</td>\n",
       "      <td>10969.0</td>\n",
       "      <td>10969.01</td>\n",
       "      <td>10969.01</td>\n",
       "      <td>10969.00</td>\n",
       "      <td>0.111542</td>\n",
       "      <td>0.195409</td>\n",
       "      <td>607130.0</td>\n",
       "      <td>0.113258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1519997700</td>\n",
       "      <td>10969.0</td>\n",
       "      <td>10969.00</td>\n",
       "      <td>10969.00</td>\n",
       "      <td>10969.00</td>\n",
       "      <td>0.504804</td>\n",
       "      <td>0.195409</td>\n",
       "      <td>607131.0</td>\n",
       "      <td>0.113258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1519997760</td>\n",
       "      <td>10965.0</td>\n",
       "      <td>10965.01</td>\n",
       "      <td>10965.00</td>\n",
       "      <td>10965.01</td>\n",
       "      <td>0.622844</td>\n",
       "      <td>0.195409</td>\n",
       "      <td>607135.0</td>\n",
       "      <td>0.113258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1519997820</td>\n",
       "      <td>10965.0</td>\n",
       "      <td>10965.00</td>\n",
       "      <td>10965.00</td>\n",
       "      <td>10965.00</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.195408</td>\n",
       "      <td>607140.0</td>\n",
       "      <td>0.113258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1519997880</td>\n",
       "      <td>10964.8</td>\n",
       "      <td>10964.81</td>\n",
       "      <td>10964.81</td>\n",
       "      <td>10964.80</td>\n",
       "      <td>0.762078</td>\n",
       "      <td>0.195451</td>\n",
       "      <td>607349.0</td>\n",
       "      <td>0.113258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time      low      high      open     close    volume  tw_sentiment  \\\n",
       "0  1519997640  10969.0  10969.01  10969.01  10969.00  0.111542      0.195409   \n",
       "1  1519997700  10969.0  10969.00  10969.00  10969.00  0.504804      0.195409   \n",
       "2  1519997760  10965.0  10965.01  10965.00  10965.01  0.622844      0.195409   \n",
       "3  1519997820  10965.0  10965.00  10965.00  10965.00  0.036500      0.195408   \n",
       "4  1519997880  10964.8  10964.81  10964.81  10964.80  0.762078      0.195451   \n",
       "\n",
       "   tw_followers  reddit_sentiment  \n",
       "0      607130.0          0.113258  \n",
       "1      607131.0          0.113258  \n",
       "2      607135.0          0.113258  \n",
       "3      607140.0          0.113258  \n",
       "4      607349.0          0.113258  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv', \n",
    "                 names=['time', 'low', 'high', 'open', 'close', 'volume', 'tw_sentiment', 'tw_followers', 'reddit_sentiment']\n",
    "                )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tw_sentiment</th>\n",
       "      <th>tw_followers</th>\n",
       "      <th>reddit_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.916000e+03</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2916.000000</td>\n",
       "      <td>2.916000e+03</td>\n",
       "      <td>2916.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.520085e+09</td>\n",
       "      <td>11208.211187</td>\n",
       "      <td>11210.622082</td>\n",
       "      <td>11209.395103</td>\n",
       "      <td>11209.469516</td>\n",
       "      <td>1.465436</td>\n",
       "      <td>0.054805</td>\n",
       "      <td>1.029932e+06</td>\n",
       "      <td>0.138590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.051409e+04</td>\n",
       "      <td>184.535842</td>\n",
       "      <td>184.280898</td>\n",
       "      <td>184.414286</td>\n",
       "      <td>184.417351</td>\n",
       "      <td>1.933775</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>2.495668e+05</td>\n",
       "      <td>0.022375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.519998e+09</td>\n",
       "      <td>10765.000000</td>\n",
       "      <td>10786.810000</td>\n",
       "      <td>10785.010000</td>\n",
       "      <td>10782.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>4.487650e+05</td>\n",
       "      <td>0.059554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.520041e+09</td>\n",
       "      <td>11102.110000</td>\n",
       "      <td>11108.187500</td>\n",
       "      <td>11102.120000</td>\n",
       "      <td>11102.120000</td>\n",
       "      <td>0.301699</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>8.856165e+05</td>\n",
       "      <td>0.123677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.520085e+09</td>\n",
       "      <td>11247.995000</td>\n",
       "      <td>11250.000000</td>\n",
       "      <td>11249.990000</td>\n",
       "      <td>11249.895000</td>\n",
       "      <td>0.871491</td>\n",
       "      <td>0.051242</td>\n",
       "      <td>1.025358e+06</td>\n",
       "      <td>0.138813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.520129e+09</td>\n",
       "      <td>11343.022500</td>\n",
       "      <td>11345.000000</td>\n",
       "      <td>11343.870000</td>\n",
       "      <td>11343.862500</td>\n",
       "      <td>1.887434</td>\n",
       "      <td>0.082558</td>\n",
       "      <td>1.179284e+06</td>\n",
       "      <td>0.157332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.520173e+09</td>\n",
       "      <td>11492.370000</td>\n",
       "      <td>11493.750000</td>\n",
       "      <td>11493.750000</td>\n",
       "      <td>11493.740000</td>\n",
       "      <td>23.988752</td>\n",
       "      <td>0.195451</td>\n",
       "      <td>1.707796e+06</td>\n",
       "      <td>0.176271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time           low          high          open         close  \\\n",
       "count  2.916000e+03   2916.000000   2916.000000   2916.000000   2916.000000   \n",
       "mean   1.520085e+09  11208.211187  11210.622082  11209.395103  11209.469516   \n",
       "std    5.051409e+04    184.535842    184.280898    184.414286    184.417351   \n",
       "min    1.519998e+09  10765.000000  10786.810000  10785.010000  10782.000000   \n",
       "25%    1.520041e+09  11102.110000  11108.187500  11102.120000  11102.120000   \n",
       "50%    1.520085e+09  11247.995000  11250.000000  11249.990000  11249.895000   \n",
       "75%    1.520129e+09  11343.022500  11345.000000  11343.870000  11343.862500   \n",
       "max    1.520173e+09  11492.370000  11493.750000  11493.750000  11493.740000   \n",
       "\n",
       "            volume  tw_sentiment  tw_followers  reddit_sentiment  \n",
       "count  2916.000000   2916.000000  2.916000e+03       2916.000000  \n",
       "mean      1.465436      0.054805  1.029932e+06          0.138590  \n",
       "std       1.933775      0.040701  2.495668e+05          0.022375  \n",
       "min       0.000111     -0.004737  4.487650e+05          0.059554  \n",
       "25%       0.301699      0.024063  8.856165e+05          0.123677  \n",
       "50%       0.871491      0.051242  1.025358e+06          0.138813  \n",
       "75%       1.887434      0.082558  1.179284e+06          0.157332  \n",
       "max      23.988752      0.195451  1.707796e+06          0.176271  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tw_sentiment</th>\n",
       "      <th>tw_followers</th>\n",
       "      <th>reddit_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499446</td>\n",
       "      <td>0.500118</td>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.499724</td>\n",
       "      <td>-0.137953</td>\n",
       "      <td>-0.561647</td>\n",
       "      <td>-0.072501</td>\n",
       "      <td>0.077858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>0.499446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.999698</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>-0.023734</td>\n",
       "      <td>0.124308</td>\n",
       "      <td>-0.113395</td>\n",
       "      <td>0.407335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.500118</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>0.124091</td>\n",
       "      <td>-0.113692</td>\n",
       "      <td>0.407504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0.499677</td>\n",
       "      <td>0.999698</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>-0.017966</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>-0.114060</td>\n",
       "      <td>0.407544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0.499724</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016847</td>\n",
       "      <td>0.124246</td>\n",
       "      <td>-0.113091</td>\n",
       "      <td>0.407347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>-0.137953</td>\n",
       "      <td>-0.023734</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>-0.017966</td>\n",
       "      <td>-0.016847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075835</td>\n",
       "      <td>0.092125</td>\n",
       "      <td>-0.055702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tw_sentiment</th>\n",
       "      <td>-0.561647</td>\n",
       "      <td>0.124308</td>\n",
       "      <td>0.124091</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.124246</td>\n",
       "      <td>0.075835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182525</td>\n",
       "      <td>0.295501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tw_followers</th>\n",
       "      <td>-0.072501</td>\n",
       "      <td>-0.113395</td>\n",
       "      <td>-0.113692</td>\n",
       "      <td>-0.114060</td>\n",
       "      <td>-0.113091</td>\n",
       "      <td>0.092125</td>\n",
       "      <td>-0.182525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_sentiment</th>\n",
       "      <td>0.077858</td>\n",
       "      <td>0.407335</td>\n",
       "      <td>0.407504</td>\n",
       "      <td>0.407544</td>\n",
       "      <td>0.407347</td>\n",
       "      <td>-0.055702</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>-0.045426</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time       low      high      open     close    volume  \\\n",
       "time              1.000000  0.499446  0.500118  0.499677  0.499724 -0.137953   \n",
       "low               0.499446  1.000000  0.999496  0.999698  0.999786 -0.023734   \n",
       "high              0.500118  0.999496  1.000000  0.999763  0.999745 -0.011507   \n",
       "open              0.499677  0.999698  0.999763  1.000000  0.999539 -0.017966   \n",
       "close             0.499724  0.999786  0.999745  0.999539  1.000000 -0.016847   \n",
       "volume           -0.137953 -0.023734 -0.011507 -0.017966 -0.016847  1.000000   \n",
       "tw_sentiment     -0.561647  0.124308  0.124091  0.124464  0.124246  0.075835   \n",
       "tw_followers     -0.072501 -0.113395 -0.113692 -0.114060 -0.113091  0.092125   \n",
       "reddit_sentiment  0.077858  0.407335  0.407504  0.407544  0.407347 -0.055702   \n",
       "\n",
       "                  tw_sentiment  tw_followers  reddit_sentiment  \n",
       "time                 -0.561647     -0.072501          0.077858  \n",
       "low                   0.124308     -0.113395          0.407335  \n",
       "high                  0.124091     -0.113692          0.407504  \n",
       "open                  0.124464     -0.114060          0.407544  \n",
       "close                 0.124246     -0.113091          0.407347  \n",
       "volume                0.075835      0.092125         -0.055702  \n",
       "tw_sentiment          1.000000     -0.182525          0.295501  \n",
       "tw_followers         -0.182525      1.000000         -0.045426  \n",
       "reddit_sentiment      0.295501     -0.045426          1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10b1b4c88>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f25748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(df['close'], 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['open', 'reddit_sentiment', 'tw_sentiment', 'tw_followers']]\n",
    "y = df['close'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scale = scalerX.fit_transform(X)\n",
    "y_scale = scalerY.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y_scale, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 1, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 200)            164000    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 485,001\n",
      "Trainable params: 485,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2041 samples, validate on 875 samples\n",
      "Epoch 1/400\n",
      "2041/2041 [==============================] - 2s 1ms/step - loss: 0.6779 - val_loss: 0.6819\n",
      "Epoch 2/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.6596 - val_loss: 0.6650\n",
      "Epoch 3/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.6415 - val_loss: 0.6479\n",
      "Epoch 4/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.6233 - val_loss: 0.6303\n",
      "Epoch 5/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.6045 - val_loss: 0.6120\n",
      "Epoch 6/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.5852 - val_loss: 0.5927\n",
      "Epoch 7/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.5650 - val_loss: 0.5724\n",
      "Epoch 8/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.5438 - val_loss: 0.5507\n",
      "Epoch 9/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.5221 - val_loss: 0.5275\n",
      "Epoch 10/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.5000 - val_loss: 0.5027\n",
      "Epoch 11/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.4774 - val_loss: 0.4761\n",
      "Epoch 12/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.4542 - val_loss: 0.4476\n",
      "Epoch 13/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.4304 - val_loss: 0.4171\n",
      "Epoch 14/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.4052 - val_loss: 0.3843\n",
      "Epoch 15/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.3798 - val_loss: 0.3490\n",
      "Epoch 16/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.3552 - val_loss: 0.3116\n",
      "Epoch 17/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.3345 - val_loss: 0.2723\n",
      "Epoch 18/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.3136 - val_loss: 0.2309\n",
      "Epoch 19/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.2936 - val_loss: 0.1895\n",
      "Epoch 20/400\n",
      "2041/2041 [==============================] - 0s 76us/step - loss: 0.2714 - val_loss: 0.1527\n",
      "Epoch 21/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.2532 - val_loss: 0.1287\n",
      "Epoch 22/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.2369 - val_loss: 0.1282\n",
      "Epoch 23/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.2341 - val_loss: 0.1397\n",
      "Epoch 24/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.2482 - val_loss: 0.1505\n",
      "Epoch 25/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.2600 - val_loss: 0.1556\n",
      "Epoch 26/400\n",
      "2041/2041 [==============================] - 0s 82us/step - loss: 0.2685 - val_loss: 0.1541\n",
      "Epoch 27/400\n",
      "2041/2041 [==============================] - 0s 75us/step - loss: 0.2648 - val_loss: 0.1473\n",
      "Epoch 28/400\n",
      "2041/2041 [==============================] - 0s 75us/step - loss: 0.2556 - val_loss: 0.1377\n",
      "Epoch 29/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.2416 - val_loss: 0.1271\n",
      "Epoch 30/400\n",
      "2041/2041 [==============================] - 0s 76us/step - loss: 0.2286 - val_loss: 0.1180\n",
      "Epoch 31/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.2165 - val_loss: 0.1127\n",
      "Epoch 32/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.2132 - val_loss: 0.1120\n",
      "Epoch 33/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2131 - val_loss: 0.1154\n",
      "Epoch 34/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2142 - val_loss: 0.1199\n",
      "Epoch 35/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.2143 - val_loss: 0.1237\n",
      "Epoch 36/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2159 - val_loss: 0.1254\n",
      "Epoch 37/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.2152 - val_loss: 0.1246\n",
      "Epoch 38/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.2130 - val_loss: 0.1215\n",
      "Epoch 39/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2106 - val_loss: 0.1165\n",
      "Epoch 40/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2055 - val_loss: 0.1106\n",
      "Epoch 41/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.2012 - val_loss: 0.1048\n",
      "Epoch 42/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.1945 - val_loss: 0.1003\n",
      "Epoch 43/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.1894 - val_loss: 0.0985\n",
      "Epoch 44/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.1874 - val_loss: 0.0982\n",
      "Epoch 45/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.1827 - val_loss: 0.0987\n",
      "Epoch 46/400\n",
      "2041/2041 [==============================] - 0s 58us/step - loss: 0.1823 - val_loss: 0.0992\n",
      "Epoch 47/400\n",
      "2041/2041 [==============================] - 0s 54us/step - loss: 0.1818 - val_loss: 0.0989\n",
      "Epoch 48/400\n",
      "2041/2041 [==============================] - 0s 56us/step - loss: 0.1813 - val_loss: 0.0977\n",
      "Epoch 49/400\n",
      "2041/2041 [==============================] - 0s 58us/step - loss: 0.1785 - val_loss: 0.0957\n",
      "Epoch 50/400\n",
      "2041/2041 [==============================] - 0s 57us/step - loss: 0.1756 - val_loss: 0.0933\n",
      "Epoch 51/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.1714 - val_loss: 0.0910\n",
      "Epoch 52/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.1675 - val_loss: 0.0893\n",
      "Epoch 53/400\n",
      "2041/2041 [==============================] - 0s 58us/step - loss: 0.1666 - val_loss: 0.0881\n",
      "Epoch 54/400\n",
      "2041/2041 [==============================] - 0s 57us/step - loss: 0.1639 - val_loss: 0.0880\n",
      "Epoch 55/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.1618 - val_loss: 0.0882\n",
      "Epoch 56/400\n",
      "2041/2041 [==============================] - 0s 59us/step - loss: 0.1581 - val_loss: 0.0881\n",
      "Epoch 57/400\n",
      "2041/2041 [==============================] - 0s 57us/step - loss: 0.1584 - val_loss: 0.0875\n",
      "Epoch 58/400\n",
      "2041/2041 [==============================] - 0s 59us/step - loss: 0.1531 - val_loss: 0.0861\n",
      "Epoch 59/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.1508 - val_loss: 0.0841\n",
      "Epoch 60/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.1482 - val_loss: 0.0821\n",
      "Epoch 61/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.1450 - val_loss: 0.0803\n",
      "Epoch 62/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.1412 - val_loss: 0.0790\n",
      "Epoch 63/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.1380 - val_loss: 0.0779\n",
      "Epoch 64/400\n",
      "2041/2041 [==============================] - 0s 59us/step - loss: 0.1348 - val_loss: 0.0769\n",
      "Epoch 65/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.1331 - val_loss: 0.0758\n",
      "Epoch 66/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.1303 - val_loss: 0.0746\n",
      "Epoch 67/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.1260 - val_loss: 0.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.1226 - val_loss: 0.0726\n",
      "Epoch 69/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.1193 - val_loss: 0.0722\n",
      "Epoch 70/400\n",
      "2041/2041 [==============================] - 0s 57us/step - loss: 0.1170 - val_loss: 0.0724\n",
      "Epoch 71/400\n",
      "2041/2041 [==============================] - 0s 55us/step - loss: 0.1155 - val_loss: 0.0730\n",
      "Epoch 72/400\n",
      "2041/2041 [==============================] - 0s 55us/step - loss: 0.1101 - val_loss: 0.0731\n",
      "Epoch 73/400\n",
      "2041/2041 [==============================] - 0s 59us/step - loss: 0.1057 - val_loss: 0.0725\n",
      "Epoch 74/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.1027 - val_loss: 0.0710\n",
      "Epoch 75/400\n",
      "2041/2041 [==============================] - 0s 59us/step - loss: 0.1002 - val_loss: 0.0690\n",
      "Epoch 76/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0948 - val_loss: 0.0667\n",
      "Epoch 77/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0924 - val_loss: 0.0643\n",
      "Epoch 78/400\n",
      "2041/2041 [==============================] - 0s 82us/step - loss: 0.0884 - val_loss: 0.0617\n",
      "Epoch 79/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.0888 - val_loss: 0.0597\n",
      "Epoch 80/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0837 - val_loss: 0.0581\n",
      "Epoch 81/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0826 - val_loss: 0.0571\n",
      "Epoch 82/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0795 - val_loss: 0.0563\n",
      "Epoch 83/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0779 - val_loss: 0.0555\n",
      "Epoch 84/400\n",
      "2041/2041 [==============================] - 0s 95us/step - loss: 0.0762 - val_loss: 0.0545\n",
      "Epoch 85/400\n",
      "2041/2041 [==============================] - 0s 91us/step - loss: 0.0763 - val_loss: 0.0527\n",
      "Epoch 86/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.0741 - val_loss: 0.0501\n",
      "Epoch 87/400\n",
      "2041/2041 [==============================] - 0s 91us/step - loss: 0.0748 - val_loss: 0.0485\n",
      "Epoch 88/400\n",
      "2041/2041 [==============================] - 0s 98us/step - loss: 0.0721 - val_loss: 0.0477\n",
      "Epoch 89/400\n",
      "2041/2041 [==============================] - 0s 92us/step - loss: 0.0727 - val_loss: 0.0473\n",
      "Epoch 90/400\n",
      "2041/2041 [==============================] - 0s 89us/step - loss: 0.0710 - val_loss: 0.0464\n",
      "Epoch 91/400\n",
      "2041/2041 [==============================] - 0s 93us/step - loss: 0.0682 - val_loss: 0.0448\n",
      "Epoch 92/400\n",
      "2041/2041 [==============================] - 0s 75us/step - loss: 0.0677 - val_loss: 0.0432\n",
      "Epoch 93/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0678 - val_loss: 0.0421\n",
      "Epoch 94/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0654 - val_loss: 0.0413\n",
      "Epoch 95/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0658 - val_loss: 0.0416\n",
      "Epoch 96/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0627 - val_loss: 0.0435\n",
      "Epoch 97/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0623 - val_loss: 0.0446\n",
      "Epoch 98/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0616 - val_loss: 0.0439\n",
      "Epoch 99/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0622 - val_loss: 0.0407\n",
      "Epoch 100/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0608 - val_loss: 0.0382\n",
      "Epoch 101/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0615 - val_loss: 0.0371\n",
      "Epoch 102/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0595 - val_loss: 0.0370\n",
      "Epoch 103/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0614 - val_loss: 0.0374\n",
      "Epoch 104/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0598 - val_loss: 0.0371\n",
      "Epoch 105/400\n",
      "2041/2041 [==============================] - 0s 90us/step - loss: 0.0594 - val_loss: 0.0368\n",
      "Epoch 106/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0613 - val_loss: 0.0345\n",
      "Epoch 107/400\n",
      "2041/2041 [==============================] - 0s 106us/step - loss: 0.0600 - val_loss: 0.0323\n",
      "Epoch 108/400\n",
      "2041/2041 [==============================] - 0s 95us/step - loss: 0.0586 - val_loss: 0.0316\n",
      "Epoch 109/400\n",
      "2041/2041 [==============================] - 0s 89us/step - loss: 0.0591 - val_loss: 0.0314\n",
      "Epoch 110/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0582 - val_loss: 0.0321\n",
      "Epoch 111/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0575 - val_loss: 0.0324\n",
      "Epoch 112/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0574 - val_loss: 0.0312\n",
      "Epoch 113/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0565 - val_loss: 0.0296\n",
      "Epoch 114/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0566 - val_loss: 0.0279\n",
      "Epoch 115/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.0550 - val_loss: 0.0268\n",
      "Epoch 116/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0559 - val_loss: 0.0266\n",
      "Epoch 117/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0562 - val_loss: 0.0269\n",
      "Epoch 118/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0549 - val_loss: 0.0264\n",
      "Epoch 119/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0546 - val_loss: 0.0259\n",
      "Epoch 120/400\n",
      "2041/2041 [==============================] - 0s 76us/step - loss: 0.0547 - val_loss: 0.0256\n",
      "Epoch 121/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.0537 - val_loss: 0.0260\n",
      "Epoch 122/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0533 - val_loss: 0.0283\n",
      "Epoch 123/400\n",
      "2041/2041 [==============================] - 0s 90us/step - loss: 0.0533 - val_loss: 0.0289\n",
      "Epoch 124/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0549 - val_loss: 0.0271\n",
      "Epoch 125/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0539 - val_loss: 0.0252\n",
      "Epoch 126/400\n",
      "2041/2041 [==============================] - 0s 91us/step - loss: 0.0531 - val_loss: 0.0252\n",
      "Epoch 127/400\n",
      "2041/2041 [==============================] - 0s 89us/step - loss: 0.0530 - val_loss: 0.0280\n",
      "Epoch 128/400\n",
      "2041/2041 [==============================] - 0s 94us/step - loss: 0.0533 - val_loss: 0.0322\n",
      "Epoch 129/400\n",
      "2041/2041 [==============================] - 0s 93us/step - loss: 0.0523 - val_loss: 0.0340\n",
      "Epoch 130/400\n",
      "2041/2041 [==============================] - 0s 84us/step - loss: 0.0529 - val_loss: 0.0312\n",
      "Epoch 131/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0525 - val_loss: 0.0276\n",
      "Epoch 132/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0518 - val_loss: 0.0261\n",
      "Epoch 133/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0526 - val_loss: 0.0261\n",
      "Epoch 134/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0524 - val_loss: 0.0289\n",
      "Epoch 135/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0516 - val_loss: 0.0305\n",
      "Epoch 136/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0517 - val_loss: 0.0291\n",
      "Epoch 137/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0510 - val_loss: 0.0274\n",
      "Epoch 138/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0513 - val_loss: 0.0268\n",
      "Epoch 139/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.0517 - val_loss: 0.0266\n",
      "Epoch 140/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0516 - val_loss: 0.0266\n",
      "Epoch 141/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0503 - val_loss: 0.0273\n",
      "Epoch 142/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0507 - val_loss: 0.0283\n",
      "Epoch 143/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0503 - val_loss: 0.0277\n",
      "Epoch 144/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0512 - val_loss: 0.0252\n",
      "Epoch 145/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0484 - val_loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0493 - val_loss: 0.0256\n",
      "Epoch 147/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0493 - val_loss: 0.0282\n",
      "Epoch 148/400\n",
      "2041/2041 [==============================] - 0s 97us/step - loss: 0.0481 - val_loss: 0.0292\n",
      "Epoch 149/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0488 - val_loss: 0.0290\n",
      "Epoch 150/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0493 - val_loss: 0.0263\n",
      "Epoch 151/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0490 - val_loss: 0.0243\n",
      "Epoch 152/400\n",
      "2041/2041 [==============================] - 0s 94us/step - loss: 0.0493 - val_loss: 0.0263\n",
      "Epoch 153/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0490 - val_loss: 0.0278\n",
      "Epoch 154/400\n",
      "2041/2041 [==============================] - 0s 80us/step - loss: 0.0489 - val_loss: 0.0275\n",
      "Epoch 155/400\n",
      "2041/2041 [==============================] - 0s 102us/step - loss: 0.0494 - val_loss: 0.0260\n",
      "Epoch 156/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0490 - val_loss: 0.0258\n",
      "Epoch 157/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0475 - val_loss: 0.0256\n",
      "Epoch 158/400\n",
      "2041/2041 [==============================] - 0s 83us/step - loss: 0.0468 - val_loss: 0.0258\n",
      "Epoch 159/400\n",
      "2041/2041 [==============================] - 0s 80us/step - loss: 0.0485 - val_loss: 0.0246\n",
      "Epoch 160/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0481 - val_loss: 0.0269\n",
      "Epoch 161/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0475 - val_loss: 0.0269\n",
      "Epoch 162/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0479 - val_loss: 0.0243\n",
      "Epoch 163/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0468 - val_loss: 0.0231\n",
      "Epoch 164/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0472 - val_loss: 0.0235\n",
      "Epoch 165/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0466 - val_loss: 0.0247\n",
      "Epoch 166/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0474 - val_loss: 0.0256\n",
      "Epoch 167/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0458 - val_loss: 0.0234\n",
      "Epoch 168/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0461 - val_loss: 0.0211\n",
      "Epoch 169/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0459 - val_loss: 0.0212\n",
      "Epoch 170/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0471 - val_loss: 0.0239\n",
      "Epoch 171/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0464 - val_loss: 0.0279\n",
      "Epoch 172/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0457 - val_loss: 0.0251\n",
      "Epoch 173/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0456 - val_loss: 0.0206\n",
      "Epoch 174/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0457 - val_loss: 0.0201\n",
      "Epoch 175/400\n",
      "2041/2041 [==============================] - 0s 82us/step - loss: 0.0462 - val_loss: 0.0232\n",
      "Epoch 176/400\n",
      "2041/2041 [==============================] - 0s 97us/step - loss: 0.0463 - val_loss: 0.0267\n",
      "Epoch 177/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0461 - val_loss: 0.0236\n",
      "Epoch 178/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0457 - val_loss: 0.0205\n",
      "Epoch 179/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0460 - val_loss: 0.0219\n",
      "Epoch 180/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0455 - val_loss: 0.0244\n",
      "Epoch 181/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0443 - val_loss: 0.0255\n",
      "Epoch 182/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0451 - val_loss: 0.0248\n",
      "Epoch 183/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0452 - val_loss: 0.0209\n",
      "Epoch 184/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0448 - val_loss: 0.0196\n",
      "Epoch 185/400\n",
      "2041/2041 [==============================] - 0s 79us/step - loss: 0.0456 - val_loss: 0.0226\n",
      "Epoch 186/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0443 - val_loss: 0.0274\n",
      "Epoch 187/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0453 - val_loss: 0.0245\n",
      "Epoch 188/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0444 - val_loss: 0.0191\n",
      "Epoch 189/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0439 - val_loss: 0.0187\n",
      "Epoch 190/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0443 - val_loss: 0.0258\n",
      "Epoch 191/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.0438 - val_loss: 0.0267\n",
      "Epoch 192/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0448 - val_loss: 0.0206\n",
      "Epoch 193/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0429 - val_loss: 0.0185\n",
      "Epoch 194/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0433 - val_loss: 0.0198\n",
      "Epoch 195/400\n",
      "2041/2041 [==============================] - 0s 93us/step - loss: 0.0443 - val_loss: 0.0229\n",
      "Epoch 196/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.0437 - val_loss: 0.0218\n",
      "Epoch 197/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0430 - val_loss: 0.0211\n",
      "Epoch 198/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0428 - val_loss: 0.0211\n",
      "Epoch 199/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0428 - val_loss: 0.0200\n",
      "Epoch 200/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0429 - val_loss: 0.0202\n",
      "Epoch 201/400\n",
      "2041/2041 [==============================] - 0s 92us/step - loss: 0.0439 - val_loss: 0.0213\n",
      "Epoch 202/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0424 - val_loss: 0.0213\n",
      "Epoch 203/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0429 - val_loss: 0.0205\n",
      "Epoch 204/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0417 - val_loss: 0.0192\n",
      "Epoch 205/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0418 - val_loss: 0.0188\n",
      "Epoch 206/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0422 - val_loss: 0.0216\n",
      "Epoch 207/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0423 - val_loss: 0.0206\n",
      "Epoch 208/400\n",
      "2041/2041 [==============================] - 0s 75us/step - loss: 0.0406 - val_loss: 0.0176\n",
      "Epoch 209/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0422 - val_loss: 0.0175\n",
      "Epoch 210/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0420 - val_loss: 0.0200\n",
      "Epoch 211/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0426 - val_loss: 0.0207\n",
      "Epoch 212/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0416 - val_loss: 0.0167\n",
      "Epoch 213/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0427 - val_loss: 0.0160\n",
      "Epoch 214/400\n",
      "2041/2041 [==============================] - 0s 80us/step - loss: 0.0421 - val_loss: 0.0202\n",
      "Epoch 215/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0403 - val_loss: 0.0238\n",
      "Epoch 216/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0419 - val_loss: 0.0179\n",
      "Epoch 217/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0414 - val_loss: 0.0159\n",
      "Epoch 218/400\n",
      "2041/2041 [==============================] - 0s 82us/step - loss: 0.0413 - val_loss: 0.0191\n",
      "Epoch 219/400\n",
      "2041/2041 [==============================] - 0s 94us/step - loss: 0.0416 - val_loss: 0.0216\n",
      "Epoch 220/400\n",
      "2041/2041 [==============================] - 0s 97us/step - loss: 0.0409 - val_loss: 0.0198\n",
      "Epoch 221/400\n",
      "2041/2041 [==============================] - 0s 93us/step - loss: 0.0406 - val_loss: 0.0160\n",
      "Epoch 222/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0409 - val_loss: 0.0173\n",
      "Epoch 223/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0404 - val_loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0401 - val_loss: 0.0187\n",
      "Epoch 225/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0409 - val_loss: 0.0160\n",
      "Epoch 226/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0410 - val_loss: 0.0164\n",
      "Epoch 227/400\n",
      "2041/2041 [==============================] - 0s 102us/step - loss: 0.0398 - val_loss: 0.0196\n",
      "Epoch 228/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0411 - val_loss: 0.0218\n",
      "Epoch 229/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0402 - val_loss: 0.0160\n",
      "Epoch 230/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0406 - val_loss: 0.0156\n",
      "Epoch 231/400\n",
      "2041/2041 [==============================] - 0s 90us/step - loss: 0.0395 - val_loss: 0.0176\n",
      "Epoch 232/400\n",
      "2041/2041 [==============================] - 0s 90us/step - loss: 0.0404 - val_loss: 0.0184\n",
      "Epoch 233/400\n",
      "2041/2041 [==============================] - 0s 82us/step - loss: 0.0397 - val_loss: 0.0196\n",
      "Epoch 234/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0397 - val_loss: 0.0180\n",
      "Epoch 235/400\n",
      "2041/2041 [==============================] - 0s 87us/step - loss: 0.0403 - val_loss: 0.0155\n",
      "Epoch 236/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0404 - val_loss: 0.0165\n",
      "Epoch 237/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0402 - val_loss: 0.0188\n",
      "Epoch 238/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0396 - val_loss: 0.0186\n",
      "Epoch 239/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0384 - val_loss: 0.0174\n",
      "Epoch 240/400\n",
      "2041/2041 [==============================] - 0s 87us/step - loss: 0.0396 - val_loss: 0.0160\n",
      "Epoch 241/400\n",
      "2041/2041 [==============================] - 0s 87us/step - loss: 0.0391 - val_loss: 0.0176\n",
      "Epoch 242/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0386 - val_loss: 0.0196\n",
      "Epoch 243/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0393 - val_loss: 0.0190\n",
      "Epoch 244/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0387 - val_loss: 0.0169\n",
      "Epoch 245/400\n",
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0386 - val_loss: 0.0165\n",
      "Epoch 246/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0382 - val_loss: 0.0174\n",
      "Epoch 247/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0373 - val_loss: 0.0190\n",
      "Epoch 248/400\n",
      "2041/2041 [==============================] - 0s 77us/step - loss: 0.0391 - val_loss: 0.0163\n",
      "Epoch 249/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0384 - val_loss: 0.0167\n",
      "Epoch 250/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0385 - val_loss: 0.0182\n",
      "Epoch 251/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0385 - val_loss: 0.0200\n",
      "Epoch 252/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0373 - val_loss: 0.0147\n",
      "Epoch 253/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0376 - val_loss: 0.0145\n",
      "Epoch 254/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0393 - val_loss: 0.0211\n",
      "Epoch 255/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0391 - val_loss: 0.0172\n",
      "Epoch 256/400\n",
      "2041/2041 [==============================] - 0s 92us/step - loss: 0.0383 - val_loss: 0.0139\n",
      "Epoch 257/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0393 - val_loss: 0.0160\n",
      "Epoch 258/400\n",
      "2041/2041 [==============================] - 0s 87us/step - loss: 0.0387 - val_loss: 0.0209\n",
      "Epoch 259/400\n",
      "2041/2041 [==============================] - 0s 94us/step - loss: 0.0378 - val_loss: 0.0162\n",
      "Epoch 260/400\n",
      "2041/2041 [==============================] - 0s 98us/step - loss: 0.0379 - val_loss: 0.0129\n",
      "Epoch 261/400\n",
      "2041/2041 [==============================] - 0s 92us/step - loss: 0.0390 - val_loss: 0.0160\n",
      "Epoch 262/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0378 - val_loss: 0.0208\n",
      "Epoch 263/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0385 - val_loss: 0.0179\n",
      "Epoch 264/400\n",
      "2041/2041 [==============================] - 0s 95us/step - loss: 0.0364 - val_loss: 0.0131\n",
      "Epoch 265/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0373 - val_loss: 0.0132\n",
      "Epoch 266/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0381 - val_loss: 0.0192\n",
      "Epoch 267/400\n",
      "2041/2041 [==============================] - 0s 84us/step - loss: 0.0372 - val_loss: 0.0159\n",
      "Epoch 268/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0378 - val_loss: 0.0129\n",
      "Epoch 269/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0373 - val_loss: 0.0164\n",
      "Epoch 270/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0367 - val_loss: 0.0201\n",
      "Epoch 271/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0382 - val_loss: 0.0149\n",
      "Epoch 272/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0378 - val_loss: 0.0124\n",
      "Epoch 273/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0370 - val_loss: 0.0163\n",
      "Epoch 274/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0371 - val_loss: 0.0215\n",
      "Epoch 275/400\n",
      "2041/2041 [==============================] - 0s 104us/step - loss: 0.0365 - val_loss: 0.0142\n",
      "Epoch 276/400\n",
      "2041/2041 [==============================] - 0s 96us/step - loss: 0.0369 - val_loss: 0.0135\n",
      "Epoch 277/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0383 - val_loss: 0.0158\n",
      "Epoch 278/400\n",
      "2041/2041 [==============================] - 0s 85us/step - loss: 0.0364 - val_loss: 0.0234\n",
      "Epoch 279/400\n",
      "2041/2041 [==============================] - 0s 98us/step - loss: 0.0374 - val_loss: 0.0140\n",
      "Epoch 280/400\n",
      "2041/2041 [==============================] - 0s 110us/step - loss: 0.0361 - val_loss: 0.0137\n",
      "Epoch 281/400\n",
      "2041/2041 [==============================] - 0s 75us/step - loss: 0.0380 - val_loss: 0.0129\n",
      "Epoch 282/400\n",
      "2041/2041 [==============================] - 0s 96us/step - loss: 0.0366 - val_loss: 0.0226\n",
      "Epoch 283/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0371 - val_loss: 0.0179\n",
      "Epoch 284/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0374 - val_loss: 0.0122\n",
      "Epoch 285/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0375 - val_loss: 0.0131\n",
      "Epoch 286/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0370 - val_loss: 0.0219\n",
      "Epoch 287/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0360 - val_loss: 0.0174\n",
      "Epoch 288/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0365 - val_loss: 0.0123\n",
      "Epoch 289/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0373 - val_loss: 0.0135\n",
      "Epoch 290/400\n",
      "2041/2041 [==============================] - 0s 106us/step - loss: 0.0359 - val_loss: 0.0209\n",
      "Epoch 291/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0374 - val_loss: 0.0177\n",
      "Epoch 292/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0363 - val_loss: 0.0117\n",
      "Epoch 293/400\n",
      "2041/2041 [==============================] - 0s 96us/step - loss: 0.0364 - val_loss: 0.0120\n",
      "Epoch 294/400\n",
      "2041/2041 [==============================] - 0s 73us/step - loss: 0.0350 - val_loss: 0.0205\n",
      "Epoch 295/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0368 - val_loss: 0.0169\n",
      "Epoch 296/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0361 - val_loss: 0.0116\n",
      "Epoch 297/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0359 - val_loss: 0.0123\n",
      "Epoch 298/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0356 - val_loss: 0.0197\n",
      "Epoch 299/400\n",
      "2041/2041 [==============================] - 0s 71us/step - loss: 0.0351 - val_loss: 0.0180\n",
      "Epoch 300/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0353 - val_loss: 0.0121\n",
      "Epoch 301/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0358 - val_loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0349 - val_loss: 0.0167\n",
      "Epoch 303/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0346 - val_loss: 0.0158\n",
      "Epoch 304/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0352 - val_loss: 0.0118\n",
      "Epoch 305/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0351 - val_loss: 0.0124\n",
      "Epoch 306/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0355 - val_loss: 0.0179\n",
      "Epoch 307/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0348 - val_loss: 0.0133\n",
      "Epoch 308/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0348 - val_loss: 0.0110\n",
      "Epoch 309/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0362 - val_loss: 0.0146\n",
      "Epoch 310/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0350 - val_loss: 0.0169\n",
      "Epoch 311/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0350 - val_loss: 0.0147\n",
      "Epoch 312/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0348 - val_loss: 0.0109\n",
      "Epoch 313/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0349 - val_loss: 0.0122\n",
      "Epoch 314/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0345 - val_loss: 0.0171\n",
      "Epoch 315/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0347 - val_loss: 0.0160\n",
      "Epoch 316/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0352 - val_loss: 0.0108\n",
      "Epoch 317/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0355 - val_loss: 0.0120\n",
      "Epoch 318/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0339 - val_loss: 0.0187\n",
      "Epoch 319/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0355 - val_loss: 0.0132\n",
      "Epoch 320/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0344 - val_loss: 0.0108\n",
      "Epoch 321/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0355 - val_loss: 0.0134\n",
      "Epoch 322/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0343 - val_loss: 0.0182\n",
      "Epoch 323/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0354 - val_loss: 0.0116\n",
      "Epoch 324/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0338 - val_loss: 0.0106\n",
      "Epoch 325/400\n",
      "2041/2041 [==============================] - 0s 74us/step - loss: 0.0349 - val_loss: 0.0134\n",
      "Epoch 326/400\n",
      "2041/2041 [==============================] - 0s 110us/step - loss: 0.0338 - val_loss: 0.0141\n",
      "Epoch 327/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0346 - val_loss: 0.0118\n",
      "Epoch 328/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0344 - val_loss: 0.0122\n",
      "Epoch 329/400\n",
      "2041/2041 [==============================] - 0s 104us/step - loss: 0.0333 - val_loss: 0.0136\n",
      "Epoch 330/400\n",
      "2041/2041 [==============================] - 0s 93us/step - loss: 0.0336 - val_loss: 0.0124\n",
      "Epoch 331/400\n",
      "2041/2041 [==============================] - 0s 96us/step - loss: 0.0332 - val_loss: 0.0107\n",
      "Epoch 332/400\n",
      "2041/2041 [==============================] - 0s 104us/step - loss: 0.0340 - val_loss: 0.0133\n",
      "Epoch 333/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0335 - val_loss: 0.0136\n",
      "Epoch 334/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0331 - val_loss: 0.0105\n",
      "Epoch 335/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0342 - val_loss: 0.0123\n",
      "Epoch 336/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0336 - val_loss: 0.0143\n",
      "Epoch 337/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0337 - val_loss: 0.0116\n",
      "Epoch 338/400\n",
      "2041/2041 [==============================] - 0s 115us/step - loss: 0.0334 - val_loss: 0.0104\n",
      "Epoch 339/400\n",
      "2041/2041 [==============================] - 0s 109us/step - loss: 0.0343 - val_loss: 0.0151\n",
      "Epoch 340/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0330 - val_loss: 0.0150\n",
      "Epoch 341/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0328 - val_loss: 0.0102\n",
      "Epoch 342/400\n",
      "2041/2041 [==============================] - 0s 100us/step - loss: 0.0337 - val_loss: 0.0105\n",
      "Epoch 343/400\n",
      "2041/2041 [==============================] - 0s 78us/step - loss: 0.0345 - val_loss: 0.0185\n",
      "Epoch 344/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0342 - val_loss: 0.0132\n",
      "Epoch 345/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0334 - val_loss: 0.0100\n",
      "Epoch 346/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0342 - val_loss: 0.0148\n",
      "Epoch 347/400\n",
      "2041/2041 [==============================] - 0s 107us/step - loss: 0.0326 - val_loss: 0.0193\n",
      "Epoch 348/400\n",
      "2041/2041 [==============================] - 0s 106us/step - loss: 0.0337 - val_loss: 0.0132\n",
      "Epoch 349/400\n",
      "2041/2041 [==============================] - 0s 109us/step - loss: 0.0333 - val_loss: 0.0102\n",
      "Epoch 350/400\n",
      "2041/2041 [==============================] - 0s 108us/step - loss: 0.0338 - val_loss: 0.0131\n",
      "Epoch 351/400\n",
      "2041/2041 [==============================] - 0s 81us/step - loss: 0.0334 - val_loss: 0.0180\n",
      "Epoch 352/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0352 - val_loss: 0.0117\n",
      "Epoch 353/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0336 - val_loss: 0.0100\n",
      "Epoch 354/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0333 - val_loss: 0.0148\n",
      "Epoch 355/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0330 - val_loss: 0.0159\n",
      "Epoch 356/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0330 - val_loss: 0.0106\n",
      "Epoch 357/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0334 - val_loss: 0.0109\n",
      "Epoch 358/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0333 - val_loss: 0.0174\n",
      "Epoch 359/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0337 - val_loss: 0.0124\n",
      "Epoch 360/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0323 - val_loss: 0.0118\n",
      "Epoch 361/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0351 - val_loss: 0.0134\n",
      "Epoch 362/400\n",
      "2041/2041 [==============================] - 0s 65us/step - loss: 0.0327 - val_loss: 0.0188\n",
      "Epoch 363/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0332 - val_loss: 0.0113\n",
      "Epoch 364/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0332 - val_loss: 0.0095\n",
      "Epoch 365/400\n",
      "2041/2041 [==============================] - 0s 88us/step - loss: 0.0333 - val_loss: 0.0150\n",
      "Epoch 366/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0325 - val_loss: 0.0180\n",
      "Epoch 367/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0338 - val_loss: 0.0095\n",
      "Epoch 368/400\n",
      "2041/2041 [==============================] - 0s 97us/step - loss: 0.0323 - val_loss: 0.0096\n",
      "Epoch 369/400\n",
      "2041/2041 [==============================] - 0s 103us/step - loss: 0.0334 - val_loss: 0.0166\n",
      "Epoch 370/400\n",
      "2041/2041 [==============================] - 0s 99us/step - loss: 0.0323 - val_loss: 0.0166\n",
      "Epoch 371/400\n",
      "2041/2041 [==============================] - 0s 72us/step - loss: 0.0323 - val_loss: 0.0096\n",
      "Epoch 372/400\n",
      "2041/2041 [==============================] - 0s 68us/step - loss: 0.0330 - val_loss: 0.0095\n",
      "Epoch 373/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0329 - val_loss: 0.0158\n",
      "Epoch 374/400\n",
      "2041/2041 [==============================] - 0s 80us/step - loss: 0.0319 - val_loss: 0.0176\n",
      "Epoch 375/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0325 - val_loss: 0.0104\n",
      "Epoch 376/400\n",
      "2041/2041 [==============================] - 0s 101us/step - loss: 0.0321 - val_loss: 0.0097\n",
      "Epoch 377/400\n",
      "2041/2041 [==============================] - 0s 104us/step - loss: 0.0322 - val_loss: 0.0149\n",
      "Epoch 378/400\n",
      "2041/2041 [==============================] - 0s 80us/step - loss: 0.0318 - val_loss: 0.0181\n",
      "Epoch 379/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041/2041 [==============================] - 0s 70us/step - loss: 0.0325 - val_loss: 0.0094\n",
      "Epoch 380/400\n",
      "2041/2041 [==============================] - 0s 111us/step - loss: 0.0316 - val_loss: 0.0110\n",
      "Epoch 381/400\n",
      "2041/2041 [==============================] - 0s 105us/step - loss: 0.0327 - val_loss: 0.0159\n",
      "Epoch 382/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0326 - val_loss: 0.0123\n",
      "Epoch 383/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0324 - val_loss: 0.0103\n",
      "Epoch 384/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0322 - val_loss: 0.0122\n",
      "Epoch 385/400\n",
      "2041/2041 [==============================] - 0s 87us/step - loss: 0.0315 - val_loss: 0.0163\n",
      "Epoch 386/400\n",
      "2041/2041 [==============================] - 0s 96us/step - loss: 0.0311 - val_loss: 0.0119\n",
      "Epoch 387/400\n",
      "2041/2041 [==============================] - 0s 69us/step - loss: 0.0325 - val_loss: 0.0100\n",
      "Epoch 388/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0314 - val_loss: 0.0127\n",
      "Epoch 389/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0318 - val_loss: 0.0141\n",
      "Epoch 390/400\n",
      "2041/2041 [==============================] - 0s 60us/step - loss: 0.0319 - val_loss: 0.0100\n",
      "Epoch 391/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0323 - val_loss: 0.0100\n",
      "Epoch 392/400\n",
      "2041/2041 [==============================] - 0s 67us/step - loss: 0.0328 - val_loss: 0.0149\n",
      "Epoch 393/400\n",
      "2041/2041 [==============================] - 0s 64us/step - loss: 0.0313 - val_loss: 0.0140\n",
      "Epoch 394/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0322 - val_loss: 0.0089\n",
      "Epoch 395/400\n",
      "2041/2041 [==============================] - 0s 66us/step - loss: 0.0318 - val_loss: 0.0093\n",
      "Epoch 396/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0317 - val_loss: 0.0148\n",
      "Epoch 397/400\n",
      "2041/2041 [==============================] - 0s 63us/step - loss: 0.0317 - val_loss: 0.0113\n",
      "Epoch 398/400\n",
      "2041/2041 [==============================] - 0s 62us/step - loss: 0.0313 - val_loss: 0.0093\n",
      "Epoch 399/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0314 - val_loss: 0.0115\n",
      "Epoch 400/400\n",
      "2041/2041 [==============================] - 0s 61us/step - loss: 0.0310 - val_loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1265138d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(200, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(200, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "model.fit(X_train, y_train, batch_size=X_train.shape[0], \n",
    "          epochs=400, validation_data=(X_test, y_test), shuffle=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119e694e0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCUVRFCUuaiQURVGUuKiRUBRFUeLy/wEmdofjImOujAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107ab3a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict_train = model.predict(X_train)\n",
    "y_predict_train = scalerY.inverse_transform(y_predict_train)\n",
    "\n",
    "y_predict_test = model.predict(X_test)\n",
    "y_predict_test = scalerY.inverse_transform(y_predict_test)\n",
    "\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_predict_train, y_predict_test), axis=0)\n",
    "\n",
    "plt.plot(y, 'r')\n",
    "plt.plot(y_predict_train, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Order percentage: 6.31%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from enum import Enum\n",
    "\n",
    "class Order(Enum):\n",
    "    STAY = 1\n",
    "    DOWN = 2\n",
    "    UP = 3\n",
    "\n",
    "n_error = 0\n",
    "y_predict_last = y_last = None\n",
    "for index, row in df.iterrows():\n",
    "    if y_predict_last is None:\n",
    "        y_predict_last = y_last = row['open']\n",
    "        \n",
    "    x_predict = np.array([row['open'], row['reddit_sentiment'], row['tw_sentiment'], row['tw_followers']]).reshape(1, -1)\n",
    "    x_predict = scalerX.transform(x_predict)\n",
    "    x_predict_reshaped = np.reshape(x_predict, (1, 1, 4))\n",
    "    y_predict_r = model.predict(x_predict_reshaped)\n",
    "    y_predict_r_rescaled = scalerY.inverse_transform(y_predict_r)\n",
    "\n",
    "    predict_order = real_order = Order.DOWN\n",
    "    if y_predict_last < y_predict_r_rescaled:\n",
    "        predict_order = Order.UP\n",
    "    elif y_predict_last == y_predict_r_rescaled:\n",
    "        predict_order = Order.STAY\n",
    "\n",
    "    if y_last < row['open']:\n",
    "        real_order = Order.UP\n",
    "    elif y_last == row['open']:\n",
    "        real_order = Order.STAY\n",
    "    \n",
    "    y_predict_last = y_predict_r_rescaled\n",
    "    y_last = row['open']\n",
    "    \n",
    "    if real_order != predict_order:\n",
    "        #print('predicted %s, real %s'% (predict_order, real_order))\n",
    "        n_error = n_error + 1\n",
    "        \n",
    "count = df['open'].count()\n",
    "percent = (n_error / count) * 100\n",
    "print(\"Error Order percentage: %0.2f%%\" % percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
